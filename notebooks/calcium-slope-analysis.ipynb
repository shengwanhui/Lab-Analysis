{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slope Analysis\n",
    "\n",
    "This project use the change of fluorecent intensity slope to identify responders from calcium imaging experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Steps\n",
    "\n",
    "The `getBaselineAndMaxDrugSlope` function smoothes the raw data by the moving window decided by `filterSize`, and analyzes the smoothed Ca intensity in an CSV and returns baseline slope and drug slope.\n",
    "\n",
    "The _slope of baseline_ is calculated as the linear regreasion slope during the 3 minutes period before stimulation onset.\n",
    "\n",
    "In addition, the smoothed data are separated into segments which n = regressionSize data points are included. The linear regression slope is then calculated for each segment. \n",
    "\n",
    "The _peak slope of stimulation_ is the most negative slope during the chosen stimulation period ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from os.path import basename\n",
    "import slopeTools\n",
    "import plotTools\n",
    "import statsTools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CSV Files and Filter Settings\n",
    "\n",
    "The user can list the ABF files they want to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBaselineAndMaxStimulationSlopeFromCSV(rawTimes,rawIntensity, filterSize = 15, regressionSize = 15):\n",
    "    \"\"\"\n",
    "    This method analyzes fluorecent intensuty in a CSV and returns baseline slope and stimulation slope.\n",
    "    \n",
    "    Arguments:\n",
    "        filterSize: number of points (sweeps) for the moving window average\n",
    "        regressionSize: number of points (sweeps) to use to calculate regression slopes during the stimulation range\n",
    "        \n",
    "    Returns:\n",
    "        baseline regression slope (over full range)\n",
    "        peak stimulus regression slope (regression over defined size)\n",
    "    \"\"\"\n",
    "\n",
    "    plt.plot(rawTimes, rawIntensity, '.', alpha=.5)\n",
    "    smoothIntensity, smoothTimes = statsTools.smoothY(rawIntensity, rawTimes, filterSize)\n",
    "    plt.plot(smoothTimes, smoothIntensity, '-')\n",
    "\n",
    "    # determine the time range of stimulus\n",
    "    stimulationTimeStart = rawTimes[30]\n",
    "    stimulationSearchWidth = 30 # index\n",
    "    stimulationTimeEnd = rawTimes[30 + stimulationSearchWidth]\n",
    "    plt.axvspan(stimulationTimeStart, stimulationTimeEnd, color='r', alpha=.1)\n",
    "\n",
    "    # determine baseline region based on stimulation time\n",
    "    baselineTimeStart = 0\n",
    "    baselineTimeEnd = stimulationTimeStart\n",
    "    baselineIndexStart, baselineIndexEnd = statsTools.rangeIndex(smoothTimes, baselineTimeStart, baselineTimeEnd)\n",
    "    baselineIntensity = smoothIntensity[baselineIndexStart:baselineIndexEnd]\n",
    "    plt.axvspan(baselineTimeStart, baselineTimeEnd, color='b', alpha=.1)\n",
    "\n",
    "    # isolate smoothed baseline intensity\n",
    "    baselineIntensity = smoothIntensity[baselineIndexStart:baselineIndexEnd]\n",
    "    baselineTimes = smoothTimes[baselineIndexStart:baselineIndexEnd]\n",
    "    baselineSlope, baselineIntercept, r, p, stdErr = scipy.stats.linregress(baselineTimes, baselineIntensity)\n",
    "\n",
    "    # calculate linear regression of baseline region\n",
    "    baselineRegressionXs = np.linspace(baselineTimeStart, baselineTimeEnd)\n",
    "    baselineRegressionYs = baselineRegressionXs * baselineSlope + baselineIntercept\n",
    "    plt.plot(baselineRegressionXs, baselineRegressionYs, color='b', ls='--')\n",
    "    print(f\"Baseline slope: {baselineSlope} pA/min\")\n",
    "\n",
    "    # perform a moving window linear regression on the smoothed Intensity\n",
    "    segments = statsTools.getMovingWindowSegments(smoothIntensity, regressionSize)\n",
    "    segSlopes = getAllSegmentSlopes(segments, experimentPeriod)   \n",
    "    segTimesOffset = (regressionSize * experimentPeriod)\n",
    "    segTimes = np.arange(len(segSlopes)) * experimentPeriod + segTimesOffset    \n",
    "    plt.subplot(212, sharex = ax1)\n",
    "    plt.plot(segTimes, segSlopes, '.')\n",
    "\n",
    "    # search the stimulation range for the most negative slope\n",
    "    plt.axvspan(stimulationTimeStart, stimulationTimeEnd, color='r', alpha=.1)\n",
    "    stimulationSlopeMin = statsTools.rangeMin(segSlopes, segTimes, stimulationTimeStart, stimulationTimeEnd)\n",
    "    stimulationSlopeMinIndex = segSlopes.index(stimulationSlopeMin)\n",
    "    stimulationSlopeMinTime = segTimes[stimulationSlopeMinIndex]\n",
    "    print(f\"stimulation slope: {stimulationSlopeMin} %/min\")\n",
    "    plt.axvline(stimulationSlopeMinTime, color='r', ls='--')\n",
    "    plt.axhline(stimulationSlopeMin, color='r', ls='--')\n",
    "    plt.axhline(baselineSlope, color='b', ls='--')\n",
    "\n",
    "    plt.ylabel(\"Slope (pA/min)\")\n",
    "    plt.xlabel(\"Time (minutes)\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return baselineSlope, stimulationSlopeMin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFilePaths = [R\"X:\\Data\\OT-Cre\\OT-GCaMP-nonspecific\\04-03-19 evoke OT\\04-30-2020 K-GLU analyze\\025um.xls\",\n",
    "                R\"X:\\Data\\OT-Cre\\OT-GCaMP-nonspecific\\04-03-19 evoke OT\\04-30-2020 K-GLU analyze\\050um.xls\"\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The users can decide the parameters they want for data analysis. \n",
    "\n",
    "`filterSize` decides number of points (sweeps) for the moving window average. \n",
    "\n",
    "`regressionSize` decides the number of smoothed data points used to calculate linear regression slopes during the stimulation range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterSize = 15\n",
    "regressionSize = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze All ABFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'X:\\\\Data\\\\OT-Cre\\\\OT-GCaMP-nonspecific\\\\04-03-19 evoke OT\\\\04-30-2020 K-GLU analyze\\\\025um.xls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b83117cd48fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstimulationSlopes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcsvFilePath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcsvFilePaths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mcsvData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvFilePaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsvData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mrawTimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m60\u001b[0m \u001b[1;31m#minutes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[0;32m   1137\u001b[0m         \u001b[1;31m# converting the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mread_data\u001b[1;34m(chunk_size)\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m             \u001b[1;31m# Convert each value according to its column and store\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1067\u001b[1;33m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m             \u001b[1;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m             \u001b[1;31m# Convert each value according to its column and store\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1067\u001b[1;33m             \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m             \u001b[1;31m# Then pack it according to the dtype's nesting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mfloatconv\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'0x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromhex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[0mtyp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'X:\\\\Data\\\\OT-Cre\\\\OT-GCaMP-nonspecific\\\\04-03-19 evoke OT\\\\04-30-2020 K-GLU analyze\\\\025um.xls'"
     ]
    }
   ],
   "source": [
    "baselineSlopes = []\n",
    "stimulationSlopes = []\n",
    "for csvFilePath in csvFilePaths:\n",
    "    csvData = np.loadtxt(csvFilePaths, delimiter=\",\")\n",
    "    header = csvData[0,:]\n",
    "    rawTimes = np.arange(csvData[1:,0]) *5/60 #minutes \n",
    "    print(csvData)\n",
    "    experimentPeriod = len(csvData[1:,0]) *5/ 60.0 # minutes\n",
    "    for i in range(len(header)):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        ax1 = plt.subplot(211)\n",
    "        plt.title(header[i])\n",
    "        plt.ylabel(\"dF/F(%)\")\n",
    "        rawIntensity = csvData[:,i+1]\n",
    "        baselineSlope, stimulationSlope = getBaselineAndMaxStimulationSlopeFromCSV(abfFilePath, filterSize, regressionSize)\n",
    "        baselineSlopes.append(baselineSlope)\n",
    "        stimulationSlopes.append(stimulationSlope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Baseline vs. Stimulation Slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The users can plot the basleine slope and the peak stimulation slope of each cell, and report the p-value in the title by performing a paired t-test between baseline slopes and peak stimulation slopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTools.plotPairs(baselineSlopes, stimulationSlopes, \"slopes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Responsiveness of All Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a scatter plot showing the slope difference of each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slopeThreshold = -1.5 \n",
    "stimulationEffects = []\n",
    "for i in range(len(abfIDs)):\n",
    "    stimulationEffects.append(stimulationSlopes[i] - baselineSlopes[i])\n",
    "\n",
    "plt.figure (figsize=(6, 4))\n",
    "plt.ylabel(\"Slope Difference (%/min)\")\n",
    "plt.plot(abfIDs, stimulationEffects, 'o', color = \"b\")\n",
    "plt.gca().set_xticklabels(abfIDs, rotation=45, ha='right')\n",
    "plt.axhline(slopeThreshold, color='r', ls='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Cells as Responsive vs. Non-Responsive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The users can define the <b>slopeThreshold</b>. The difference between baseline slope and peak stimulation slope must be more negative than this value to be a responder\n",
    "slopeThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulationEffects=statsTools.responderByDelta(abfIDs, stimulationEffects, slopeThreshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
