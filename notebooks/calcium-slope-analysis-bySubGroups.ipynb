{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slope Analysis\n",
    "\n",
    "This project use the change of fluorecent intensity slope to identify responders from calcium imaging experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Steps\n",
    "\n",
    "The `getBaselineAndMaxStimulationSlopeFromCSV` function smoothes the raw data by the moving window decided by `filterSize`, and analyzes the smoothed Ca intensity in an CSV and returns baseline slope and drug slope.\n",
    "\n",
    "The _slope of baseline_ is calculated as the linear regression slope during the 3 minutes period before stimulation onset.\n",
    "\n",
    "In addition, the smoothed data are separated into segments which n = regressionSize data points are included. The linear regression slope is then calculated for each segment. \n",
    "\n",
    "The _peak slope of stimulation_ is the most negative slope during the chosen stimulation period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import os\n",
    "import glob\n",
    "import slopeTools\n",
    "import plotTools\n",
    "import statsTools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas DataFrame as a Database\n",
    "\n",
    "This script creates a single dataframe containing AFU data for every structure in all experiments. \n",
    "\n",
    "Columns define group, drug, distance, structure, etc.\n",
    "\n",
    "This large dataframe can be queried as needed, or exported as a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = pd.DataFrame(columns = ['Group', 'Distance', 'MCN','Sniffer','AFU'])\n",
    "\n",
    "def addGroup(folderPath, groupName):    \n",
    "    filePaths = glob.glob(folderPath+\"/*.xls\")\n",
    "    filePaths = [x for x in filePaths if x.endswith(\"um.xls\")]\n",
    "    for filePath in filePaths:\n",
    "        fileName = os.path.basename(filePath)\n",
    "\n",
    "        addExperiment(filePath, groupName)\n",
    "        \n",
    "def addExperiment(filePath, groupName):    \n",
    "    global database   #global reads a variable outside the function\n",
    "    df = pd.read_csv(filePath, delimiter=\"\\t\")\n",
    "    roiNames = df.columns[1:] #return to the column labels \n",
    "    for roiName in roiNames:\n",
    "        mcn, distance, sniffer = roiName.split(\".\")\n",
    "        distance = int(distance.replace(\"um\", \"\"))\n",
    "        afu = df[roiName].values\n",
    "        row = {'Group': groupName, 'Distance': distance, 'MCN': mcn, 'Sniffer':sniffer, 'AFU':afu}\n",
    "        database = database.append(row,ignore_index = True)\n",
    "        \n",
    "addGroup(R\"X:\\Data\\OT-Cre\\OT-GCaMP-nonspecific\\04-03-19 evoke OT\\04-30-2020 Cs-GLU analyze\", \"CsGlu\")\n",
    "addGroup(R\"X:\\Data\\OT-Cre\\OT-GCaMP-nonspecific\\04-03-19 evoke OT\\04-30-2020 K-GLU analyze\", \"KGlu\")\n",
    "addGroup(R\"X:\\Data\\OT-Cre\\OT-GCaMP-nonspecific\\04-03-19 evoke OT\\04-30-2020 L368 - Cs analyze\", \"L368\")\n",
    "\n",
    "database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert raw AFU into dF/F (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineStartIndex = 20\n",
    "treatmentStartIndex = 30\n",
    "experimentPeriod = 5/60 #min\n",
    "dFoFs = []\n",
    "analyzed = database.copy()\n",
    "\n",
    "analyzed[\"BaselineAFUMeans\"] = [np.mean(x[baselineStartIndex:treatmentStartIndex]) for x in analyzed[\"AFU\"].values]\n",
    "for i in range(len(analyzed[\"AFU\"])):\n",
    "    dFoF = (analyzed[\"AFU\"][i]-analyzed[\"BaselineAFUMeans\"][i])*100/analyzed[\"BaselineAFUMeans\"][i]\n",
    "    dFoFs.append(dFoF)\n",
    "    \n",
    "analyzed[\"Raw dF/F (%)\"] = dFoFs\n",
    "\n",
    "analyzed = analyzed.drop(columns=[\"AFU\", \"BaselineAFUMeans\"], axis=1)\n",
    "\n",
    "\n",
    "analyzed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smooth raw data by filtersize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterSize = 5\n",
    "regressionSize = 10\n",
    "\n",
    "length = [len(x) for x in analyzed[\"Raw dF/F (%)\"].values]\n",
    "maxLength = max(length)\n",
    "time = np.arange(maxLength)*experimentPeriod \n",
    "smoothTimes = statsTools.smoothY(time, filterSize)\n",
    "analyzed[\"dF/F (%)\"] = [statsTools.smoothY(x, filterSize) for x in analyzed[\"Raw dF/F (%)\"].values]\n",
    "display(analyzed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the slope difference for each sniffer cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the calcium signal and slops over time of individual cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baselineStartIndex = 15  # index is right shifted for 2.5 indexes after smoothing\n",
    "treatmentStartIndex = 30\n",
    "treatmentDuration = 2\n",
    "\n",
    "baselineSlopes =[]\n",
    "stimulationSlopes =[]\n",
    "slopeDifference = []\n",
    "baselineTime = smoothTimes[baselineStartIndex:treatmentStartIndex]\n",
    "\n",
    "\n",
    "for index in range(len(analyzed[\"dF/F (%)\"].values)):\n",
    "    dFoF = analyzed[\"dF/F (%)\"].values[index]\n",
    "\n",
    "\n",
    "    baselineSlope, baselineIntercept, r, p, stdErr = scipy.stats.linregress(baselineTime, dFoF[baselineStartIndex:treatmentStartIndex])\n",
    "    baselineRegressionXs = np.linspace(smoothTimes[baselineStartIndex], smoothTimes[treatmentStartIndex])\n",
    "    baselineRegressionYs = baselineRegressionXs * baselineSlope + baselineIntercept\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax1 = plt.subplot(211)\n",
    "    plt.plot(smoothTimes[:len(dFoF)], dFoF, 'o-', color='b', )\n",
    "    plt.plot(baselineRegressionXs, baselineRegressionYs, color='b', ls='--')\n",
    "    plt.title(analyzed[\"Group\"].values[index]+\"-\"+str(analyzed[\"Distance\"].values[index])+\"-\"+analyzed[\"MCN\"].values[index]+analyzed[\"Sniffer\"].values[index])\n",
    "    plt.ylabel(\"dF/F (%)\")\n",
    "    \n",
    "    \n",
    "    plt.axvspan(smoothTimes[treatmentStartIndex], smoothTimes[treatmentStartIndex]+treatmentDuration, color='r', alpha=.1)\n",
    "    baselineSlopes.append(baselineSlope)\n",
    "    \n",
    "    plt.subplot(212, sharex = ax1)\n",
    "    \n",
    "    plt.ylabel(\"slope (%/min)\")\n",
    "    \n",
    "    segments = statsTools.getMovingWindowSegments(dFoF, regressionSize)\n",
    "    segSlopes = slopeTools.getAllSegmentSlopes(segments, experimentPeriod)\n",
    "    #segSlopesList.append(segSlopes)\n",
    "    segTimes = statsTools.smoothY(smoothTimes, filterSize)\n",
    "    plt.axvspan(segTimes[treatmentStartIndex], segTimes[treatmentStartIndex]+treatmentDuration, color='r', alpha=.1)\n",
    "    treatmentStartTime = segTimes[treatmentStartIndex]\n",
    "    treatmentEndTime = treatmentStartTime + treatmentDuration\n",
    "    treatmentSlopeMax = statsTools.rangeMax(segSlopes, segTimes, treatmentStartTime, treatmentEndTime)\n",
    "    treatmentSlopeMaxIndex = segSlopes.index(treatmentSlopeMax)\n",
    "    treatmentSlopeMaxTime = segTimes[treatmentSlopeMaxIndex]\n",
    "    stimulationSlopes.append(treatmentSlopeMax)   \n",
    "    plt.plot(segTimes[:len(segSlopes)], segSlopes, 'o-', color='r', )\n",
    "    plt.axhline(baselineSlope, color='b', ls='--')\n",
    "    plt.axhline(treatmentSlopeMax, color='r', ls='--')\n",
    "    \n",
    "    slopeDifference.append(treatmentSlopeMax-baselineSlope)\n",
    "\n",
    "analyzed[\"Treatment Slop (%)\"] = stimulationSlopes\n",
    "analyzed[\"SlopeDifference (%)\"] = slopeDifference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed\n",
    "analyzed.to_csv('AllSniffer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot response rate by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifyResponders(df, groupName, distance, slopeDifferenceThreshold):\n",
    "    \"\"\"\n",
    "    Given a dataframe, group, and distance, return just the cells that change\n",
    "    more than the given threshold.\n",
    "    \"\"\"\n",
    "    matching = df.loc[analyzed['Group'] == group]\n",
    "    matching = matching.loc[matching['Distance'] == distance]\n",
    "    totalCellCount = len(matching)\n",
    "    matching = matching.loc[matching['SlopeDifference (%)'] > slopeDifferenceThreshold] \n",
    "    matching = matching.loc[matching['Treatment Slop (%)'] > 5]\n",
    "    responderCount = len(matching)\n",
    "    return matching, totalCellCount, responderCount\n",
    "    \n",
    "\n",
    "groups = [\"KGlu\", \"CsGlu\", \"L368\"]\n",
    "#groups = [ \"KGlu\",\"L368\"]\n",
    "distances = [25, 50, 75, 100, 125]\n",
    "threshold = 10\n",
    "\n",
    "\n",
    "for group in groups:\n",
    "    responseByDistance = []\n",
    "    for distance in distances:\n",
    "        matching, totalCellCount, responderCount = identifyResponders(analyzed, group, distance, threshold)\n",
    "        #sniffers = sorted(list(set(matching['MCN'])))\n",
    "        responseRate = responderCount*100/totalCellCount\n",
    "        responseByDistance.append(responseRate)\n",
    "        responseDftemperol = pd.DataFrame({'Distance (µm)': [distance], 'Group': [group],'Responder': [responderCount], 'non-responder': [totalCellCount-responderCount]})\n",
    "        display(responseDftemperol)\n",
    "    plt.plot(distances, responseByDistance, 'o-', label=group)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Response Rate (%)\")\n",
    "plt.xlabel(\"Distance (µm)\")\n",
    "plt.title(f\"Threshold = {threshold}%\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group sniffers by MCNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "groups = [\"KGlu\", \"CsGlu\", \"L368\"]\n",
    "distances = [25, 50, 75, 100, 125]\n",
    "columnsForCellCounts = ['Group', 'MCN', 'Distance (µm)', 'Sniffer Count']\n",
    "cellCounts = pd.DataFrame(columns = columnsForCellCounts)\n",
    "\n",
    "for group in groups:\n",
    "    cellCounts = pd.DataFrame(columns = columnsForCellCounts)\n",
    "    mcnCount = []\n",
    "    for distance in distances:\n",
    "        matching = analyzed.loc[analyzed['Group'] == group]\n",
    "        matching = matching.loc[matching['Distance'] == distance]\n",
    "        MCNs = sorted(list(set(matching['MCN'])))\n",
    "        mcnCount.append(len(MCNs))\n",
    "        for MCN in MCNs:\n",
    "            matchingSniffer = matching.loc[matching['MCN'] == MCN]\n",
    "            matchingSnifferCount = len(matchingSniffer)\n",
    "            cellCount = pd.DataFrame({'Group': [group], 'MCN': [MCN], 'Distance (µm)': [distance], 'Sniffer Count': [matchingSnifferCount]})\n",
    "            #print(cellCount)\n",
    "            cellCounts = cellCounts.append(cellCount, ignore_index=True)\n",
    "            \n",
    "            #print(f\"{group}-{MCN} has {matchingSnifferCount} sniffers at {distance} um.\")\n",
    "    display(cellCounts)        \n",
    "    plt.plot(distances, mcnCount, 'o-', label=group)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"n number\")\n",
    "plt.xlabel(\"Distance (µm)\")\n",
    "plt.title(f\"MCN number at each distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete sniffers that show severe exponential decay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def monoExp(x, m, t, b):\n",
    "    return m * np.exp(-t * x) + b\n",
    "\n",
    "def calcRsquared(actual, expected):\n",
    "    \"\"\"Calculate rSquared discretely so we don't need sklearn.\"\"\"\n",
    "    squaredDiffs = np.power(actual - expected, 2)\n",
    "    squaredDiffsFromMean = np.power(actual - np.mean(actual), 2)\n",
    "    rSquared = 1 - np.sum(squaredDiffs) / np.sum(squaredDiffsFromMean)\n",
    "    return rSquared\n",
    "\n",
    "def exponentialDecayFit(xs, ys):\n",
    "\n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "\n",
    "    #plt.plot(xs, ys, '.')\n",
    "    \n",
    "    params, cv = curve_fit(monoExp, xs, ys,bounds=(-40, [2000, 30, 50]))\n",
    "    m, t, b = params\n",
    "    sampleRate = 20_000 # Hz\n",
    "    tauSec = (1 / t) / sampleRate\n",
    "\n",
    "    expCurveFitted = monoExp(xs, *params)\n",
    "    expRsquared = calcRsquared(ys, expCurveFitted)\n",
    "    #plt.plot(xs, monoExp(xs, m, t, b), '--', label=\"fitted\")\n",
    "    #print(expRsquared)\n",
    "    return expRsquared\n",
    "\n",
    "\n",
    "indexes =[]\n",
    "for ysIndex in range(len(analyzed[\"dF/F (%)\"])):\n",
    "    ys = analyzed[\"dF/F (%)\"].values[ysIndex]\n",
    "    xs = smoothTimes[:len(ys)]\n",
    "    rSquare = exponentialDecayFit(xs, ys)\n",
    "\n",
    "    if rSquare > 0.90:\n",
    "        indexes.append(ysIndex)\n",
    "        #analyzedCleaned = analyzed.drop(index=indexes, axis=1)\n",
    "\n",
    "\n",
    "#analyzedCleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
